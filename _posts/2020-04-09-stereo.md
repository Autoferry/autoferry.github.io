---
layout: post
title: Stereo vision for autonomous ferry
category: SF
---
## Background
An autonomous ferry can use a variety of sensors to keep track of its surroundings. These can be categorized as active sensors (radar, lidar) and passive sensors (optical and infrared cameras). The active sensors emit radiation, and can therefore measure distance as proportional to the two-way travel time. Passive sensors cannot do this, and can therefore only provide angle measurements. Nevertheless, humans are able to navigate the world with only passive sensors, namely our eyes. One reason why this works well is that eyes come in pairs, that is, in a stereo configuration. 

In contrast to the baseline between two human eyes, it is possible to mount cameras on an autonomous ferry with a baseline of several meters, enabling depth vision for distances larger than 100 meters. The full-scale autonomous ferry MilliAmpere2, currently in planning, is therefore expected to use optical stereo vision to a large extent as part of its sensor fusion system. 
Research papers from the autonomous driving community have argued that stereo vision can reach sufficient accuracy to replace lidars. 






## Scope
During the last year, two MSc students affiliated with the Autoferry project have experimented with stereo vision algorithms for the autonomous ferry application. The goal of the present project is to continue this work, and demonstrate stereo vision in the operational environment of the autonomous ferry. This can be a single-student project, or a collaboration between two or more students. The project will, at least in the early phases, use the same equipment that has been used in the on-going MSc project on stereo vision.  

## Proposed Tasks for the 5th year project

1. Mounting of stereo equipment on MilliAmpere, and integration with navigation system.
2. Verification of intrinsic calibration. Extrinsic calibration against navigation system. 
3. Experiment: Record video of other boats with ground truth through GPS and/or lidar.
4. Investigate the performance of different stereo vision algorithms with ground truth.
5. Write report.

## Proposed Tasks for the master thesis

The project work aims to be extended into a master thesis for the spring of 2021. Several directions are possible depending on the interest of the student. 

* Multi-target and extended object tracking by means of stereo vision. 
* Simultaneous localization and mapping (SLAM) by means of stereo vision. 
* Stereo vision for infrared cameras.
* Integration of stereo vision in closed-loop collision avoidance experiments. 
* Fusion of stereo vision with additional active and passive sensors. 

## Contact
For more information, contact supervisor [Edmund F. Brekke](http://www.ntnu.no/ansatte/edmundfo).
## References

* Helgesen, Ø., et al. (2020): “[Low Altitude Georeferencing for Imaging Sensors in Maritime Tracking](http://folk.ntnu.no/edmundfo/msc2019-2020/Georeferencing_paper)”, Accepted for publication at the IFAC World Congress, Berlin, Germany,
* Helgesen, Ø., et al. (2019): “[Sensor Combinations in Heterogeneous Multi-sensor Fusion for Maritime Target Tracking](https://ieeexplore.ieee.org/document/9011297)”, Proceedings of FUSION, Ottawa, Canada.
* Skjellaug, E. (2019): “[Feature-based laser odometry for autonomous ferry](http://folk.ntnu.no/edmundfo/msc2019-2020/Skjellaug-laser-odo.pdf)”, Specialization project, NTNU. 
* Ødven, M. (2019): “[Lidar-based SLAM for Autonomous Ferry](http://folk.ntnu.no/edmundfo/msc2019-2020/MasterFinalReducedMarius.pdf)”, MSc thesis, NTNU
* Pedersen, J. (2018): “[Harbor Surveillance with a K-best, Track Terminating, Hypothesis-Oriented MHT](http://folk.ntnu.no/edmundfo/msc2019-2020/masteroppgaveJesperPedersenReduced.pdf)”, MSc thesis, NTNU
